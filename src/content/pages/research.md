---
title: "Research / Projects"
summary: "Research themes and selected projects in multimodal learning, LLM optimization, and efficient ML systems."
updated: 2025-01-05
---

My research focuses on multimodal learning and alignment, large language model fine-tuning (SFT, LoRA), reinforcement learning–based optimization for LLMs, and ML systems for efficient deployment.

Academic research experience:
- Medical imaging: reduced annotation cost by fine-tuning MedCLIP-SAM to generate pseudo-labels, enabling scalable training with limited expert labels.
- Multimodal 3D classification: built a Transformer-based model that integrates MRI, clinical tabular data, and text, improving accuracy by 5.1% over single-modality baselines.
- Zero-shot segmentation: designed an M-LLM–guided distillation pipeline for camouflaged object segmentation, achieving real-time performance (18.1 FPS) under compute constraints.

Industry research experience:
- Multimodal inference: designed an end-to-end pipeline combining YOLOv11 perception with LLM-based reasoning for structured decision outputs.
- LLM optimization: optimized Qwen2.5-7B with LoRA and RL-based fine-tuning for medical report reasoning tasks.
